{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297d700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan\\AppData\\Roaming\\Python\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Aryan\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Aryan\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m text_model = SentenceTransformer(\u001b[33m'\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Generate text embeddings for descriptions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m description_embeddings = \u001b[43mtext_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Preprocessing pipeline for categorical/numerical features\u001b[39;00m\n\u001b[32m     18\u001b[39m preprocessor = ColumnTransformer([\n\u001b[32m     19\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mcat\u001b[39m\u001b[33m'\u001b[39m, OneHotEncoder(handle_unknown=\u001b[33m'\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m'\u001b[39m, sparse_output=\u001b[38;5;28;01mFalse\u001b[39;00m), \n\u001b[32m     20\u001b[39m      [\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33msub_category\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbrand\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m]),\n\u001b[32m     21\u001b[39m     (\u001b[33m'\u001b[39m\u001b[33mnum\u001b[39m\u001b[33m'\u001b[39m, MinMaxScaler(), [\u001b[33m'\u001b[39m\u001b[33msale_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarket_price\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrating\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     22\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\SentenceTransformer.py:653\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentences), batch_size, desc=\u001b[33m\"\u001b[39m\u001b[33mBatches\u001b[39m\u001b[33m\"\u001b[39m, disable=\u001b[38;5;129;01mnot\u001b[39;00m show_progress_bar):\n\u001b[32m    652\u001b[39m     sentences_batch = sentences_sorted[start_index : start_index + batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m     features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    654\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    655\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\SentenceTransformer.py:1124\u001b[39m, in \u001b[36mSentenceTransformer.tokenize\u001b[39m\u001b[34m(self, texts)\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtokenize\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m] | \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[32m   1114\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1115\u001b[39m \u001b[33;03m    Tokenizes the texts.\u001b[39;00m\n\u001b[32m   1116\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1122\u001b[39m \u001b[33;03m            \"attention_mask\", and \"token_type_ids\".\u001b[39;00m\n\u001b[32m   1123\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_first_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sentence_transformers\\models\\Transformer.py:488\u001b[39m, in \u001b[36mTransformer.tokenize\u001b[39m\u001b[34m(self, texts, padding)\u001b[39m\n\u001b[32m    486\u001b[39m batch1, batch2 = [], []\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_tuple \u001b[38;5;129;01min\u001b[39;00m texts:\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     batch1.append(\u001b[43mtext_tuple\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m    489\u001b[39m     batch2.append(text_tuple[\u001b[32m1\u001b[39m])\n\u001b[32m    490\u001b[39m to_tokenize = [batch1, batch2]\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('BigBasket Products.csv', index_col='index')\n",
    "\n",
    "# Initialize Sentence Transformer model for advanced text embeddings\n",
    "text_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generate text embeddings for descriptions\n",
    "description_embeddings = text_model.encode(df['description'].tolist())\n",
    "\n",
    "# Preprocessing pipeline for categorical/numerical features\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), \n",
    "     ['category', 'sub_category', 'brand', 'type']),\n",
    "    ('num', MinMaxScaler(), ['sale_price', 'market_price', 'rating'])\n",
    "])\n",
    "\n",
    "# Transform features\n",
    "processed_features = preprocessor.fit_transform(df)\n",
    "\n",
    "# Combine all features\n",
    "combined_features = np.hstack([\n",
    "    processed_features,\n",
    "    description_embeddings\n",
    "])\n",
    "\n",
    "# Compute similarity matrix\n",
    "cosine_sim = cosine_similarity(combined_features)\n",
    "\n",
    "# Recommendation function\n",
    "def get_recommendations(product_name, n=5):\n",
    "    try:\n",
    "        idx = df[df['product'] == product_name].index[0]\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "        sim_indices = [i[0] for i in sim_scores[1:n+1]]\n",
    "        return df[['product', 'category', 'sub_category']].iloc[sim_indices]\n",
    "    except:\n",
    "        return \"Product not found in database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f1a388",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_recommendations(\"Garlic Oil - Vegetarian Capsule 500 mg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebbcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f731114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
